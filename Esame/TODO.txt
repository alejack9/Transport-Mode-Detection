- caricamento dataset (quale dei 3?) balanced, 5 sec V
- pre-processing
  - feature extraction (min, max, avg, std in time window -> simile a binning) // gia` fatto V
  - valori mancanti				media/moda/mediana e vediamo ~~quale si discosta di piu` dai valori possibili~~ con un classificatore quale si comporta meglio media: V moda: X mediana: V
      (abbiamo scelto la mediana perche` le distribuzione sono skewed)
  - bilanciamento				no IL DATASET E` GIA` BILANCIATO V
  - discrepanze					easy -- le features con discrepanze vengono trattati come valori mancanti (se sono tante) V
      non ci sono discrepanze rilevanti, attinedoci al paper abbiamo cancellato alcune feature      
  - standardizzazione/min-max scaling		a seconda del modello (KNN, SVM, reti neurali => min-max scaling: no assunzioni su distribuzione) (gaussian e NB => standardizzazione (no QDA)) V
      si e` deciso per provare entrambe le tecniche per tutti i modelli
  - pca/lda? (se avanza tempo) PCA per tutto tranne random forest

- divisione train/val/test
  - cross-validation o hold-out validation?	Cross validation V
  - random search o grid search?		Grid aumentando la granularita` ogni volta, ma se lento andare di random
  - mlp
    - architettura				1 (per la scienza), 2 o 3 hidden layer ---- # hidden units hyperpar
    - ottimizzatore				sgd, semmai adam (B1 = 0.9, B2 = 0.999)
    - alpha					learning rate decay (hyperpars) [a=0.1,0.01,0.001]
    - numero epoche				hyperpar []
    - dimensione minibatch			hyperpar [8,16,...,256]
  - NB
  - RF
    - numero di alberi
  - SVM

 - testing
    - matrice di confusione
    - metriche varie


-----------------------------------------------------
crea estimator custom per drop colonne  P

per training
	provare senza drop P
	affinare iperparametri J
	migliorare stampa iperparametri best model P
	bar plot accuratezza per ogni best model J
	stampa decision boundary P
per testing
	bar plot accuratezza per ogni best model J
	roc curve di ogni best model  J
	in plot confusion
		disporli a griglia J